24-04-05 13:41:08.918 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr_lr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 13:41:29.246 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr_lr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 13:45:00.947 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr_lr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 13:46:17.279 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr_lr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 13:47:25.769 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr_lr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 13:48:38.419 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 13:59:55.144 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 14:01:52.614 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 14:02:14.580 : Number of train images: 165, iters: 83
24-04-05 14:02:22.053 : 
Networks name: Autoencoder
Params number: 98324797
Net structure:
Autoencoder(
  (encoder): Encoder(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (9): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (10): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (11): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (12): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (13): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (14): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (15): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (16): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (17): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (18): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (19): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (20): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (21): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (22): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (23): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (24): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (25): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (26): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc): ForwardPool(
      (layers): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SELU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=2048, out_features=4096, bias=True)
        (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): SELU()
        (7): Dropout(p=0.0, inplace=False)
        (8): Linear(in_features=4096, out_features=63, bias=True)
        (9): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): SELU()
        (11): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder): Decoder()
)

Networks name: Discriminator_UNet
Params number: 4375745
Net structure:
Discriminator_UNet(
  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

24-04-05 14:02:22.209 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.072 |  0.067 |  0.020 | torch.Size([128, 1, 4, 4]) || encoder.downsample_layers.0.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.bias
 | -0.000 | -0.095 |  0.090 |  0.020 | torch.Size([256, 128, 2, 2]) || encoder.downsample_layers.1.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.1.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.bias
 | -0.000 | -0.101 |  0.098 |  0.020 | torch.Size([512, 256, 2, 2]) || encoder.downsample_layers.2.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.2.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.bias
 | -0.000 | -0.096 |  0.095 |  0.020 | torch.Size([1024, 512, 2, 2]) || encoder.downsample_layers.3.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.downsample_layers.3.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.gamma
 | -0.000 | -0.077 |  0.068 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.bias
 | -0.000 | -0.076 |  0.079 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.0.pwconv1.bias
 | -0.000 | -0.081 |  0.083 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.gamma
 | -0.000 | -0.080 |  0.068 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.bias
 | -0.000 | -0.085 |  0.085 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.1.pwconv1.bias
 | -0.000 | -0.083 |  0.085 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.gamma
 | -0.000 | -0.077 |  0.078 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.bias
 |  0.000 | -0.077 |  0.082 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.2.pwconv1.bias
 | -0.000 | -0.080 |  0.083 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.gamma
 | -0.000 | -0.074 |  0.076 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.bias
 |  0.000 | -0.088 |  0.093 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.0.pwconv1.bias
 | -0.000 | -0.093 |  0.093 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.gamma
 | -0.000 | -0.082 |  0.079 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.bias
 | -0.000 | -0.097 |  0.099 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.1.pwconv1.bias
 |  0.000 | -0.093 |  0.096 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.gamma
 |  0.000 | -0.071 |  0.077 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.bias
 | -0.000 | -0.093 |  0.097 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.2.pwconv1.bias
 |  0.000 | -0.085 |  0.095 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.gamma
 | -0.000 | -0.077 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.bias
 | -0.000 | -0.104 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.0.pwconv1.bias
 |  0.000 | -0.094 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.gamma
 |  0.000 | -0.079 |  0.090 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.bias
 | -0.000 | -0.093 |  0.103 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.1.pwconv1.bias
 |  0.000 | -0.092 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.gamma
 | -0.000 | -0.080 |  0.089 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.bias
 |  0.000 | -0.089 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.2.pwconv1.bias
 | -0.000 | -0.092 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.gamma
 | -0.000 | -0.085 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.3.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.bias
 | -0.000 | -0.094 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.3.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.3.pwconv1.bias
 | -0.000 | -0.097 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.3.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.gamma
 |  0.000 | -0.085 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.4.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.bias
 | -0.000 | -0.093 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.4.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.4.pwconv1.bias
 |  0.000 | -0.093 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.4.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.gamma
 | -0.000 | -0.079 |  0.094 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.5.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.bias
 | -0.000 | -0.095 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.5.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.5.pwconv1.bias
 |  0.000 | -0.089 |  0.090 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.5.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.gamma
 |  0.000 | -0.083 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.6.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.bias
 |  0.000 | -0.094 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.6.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.6.pwconv1.bias
 | -0.000 | -0.099 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.6.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.gamma
 |  0.000 | -0.080 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.7.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.bias
 |  0.000 | -0.094 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.7.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.7.pwconv1.bias
 |  0.000 | -0.100 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.7.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.gamma
 |  0.000 | -0.074 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.8.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.bias
 |  0.000 | -0.100 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.8.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.8.pwconv1.bias
 | -0.000 | -0.092 |  0.104 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.8.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.gamma
 | -0.000 | -0.071 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.9.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.bias
 |  0.000 | -0.093 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.9.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.9.pwconv1.bias
 |  0.000 | -0.103 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.9.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.gamma
 | -0.000 | -0.074 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.10.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.bias
 |  0.000 | -0.092 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.10.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.10.pwconv1.bias
 |  0.000 | -0.090 |  0.105 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.10.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.gamma
 | -0.000 | -0.087 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.11.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.bias
 | -0.000 | -0.090 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.11.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.11.pwconv1.bias
 | -0.000 | -0.101 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.11.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.gamma
 | -0.000 | -0.084 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.12.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.bias
 | -0.000 | -0.107 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.12.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.12.pwconv1.bias
 |  0.000 | -0.092 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.12.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.gamma
 |  0.000 | -0.075 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.13.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.bias
 | -0.000 | -0.097 |  0.103 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.13.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.13.pwconv1.bias
 |  0.000 | -0.095 |  0.090 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.13.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.gamma
 |  0.000 | -0.084 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.14.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.bias
 |  0.000 | -0.096 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.14.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.14.pwconv1.bias
 | -0.000 | -0.096 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.14.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.gamma
 |  0.000 | -0.082 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.15.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.bias
 | -0.000 | -0.098 |  0.090 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.15.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.15.pwconv1.bias
 |  0.000 | -0.101 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.15.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.gamma
 | -0.000 | -0.082 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.16.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.bias
 |  0.000 | -0.094 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.16.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.16.pwconv1.bias
 |  0.000 | -0.092 |  0.108 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.16.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.gamma
 |  0.000 | -0.075 |  0.073 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.17.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.bias
 | -0.000 | -0.097 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.17.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.17.pwconv1.bias
 | -0.000 | -0.095 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.17.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.gamma
 |  0.000 | -0.079 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.18.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.bias
 |  0.000 | -0.093 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.18.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.18.pwconv1.bias
 | -0.000 | -0.105 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.18.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.gamma
 |  0.000 | -0.090 |  0.073 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.19.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.bias
 |  0.000 | -0.096 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.19.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.19.pwconv1.bias
 | -0.000 | -0.096 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.19.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.gamma
 | -0.000 | -0.084 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.20.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.bias
 | -0.000 | -0.090 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.20.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.20.pwconv1.bias
 |  0.000 | -0.098 |  0.111 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.20.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.gamma
 |  0.000 | -0.083 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.21.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.bias
 |  0.000 | -0.094 |  0.090 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.21.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.21.pwconv1.bias
 | -0.000 | -0.098 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.21.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.gamma
 | -0.000 | -0.083 |  0.090 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.22.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.bias
 |  0.000 | -0.103 |  0.106 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.22.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.22.pwconv1.bias
 |  0.000 | -0.094 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.22.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.gamma
 | -0.000 | -0.079 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.23.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.bias
 |  0.000 | -0.097 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.23.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.23.pwconv1.bias
 |  0.000 | -0.099 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.23.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.gamma
 | -0.000 | -0.071 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.24.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.bias
 | -0.000 | -0.093 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.24.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.24.pwconv1.bias
 | -0.000 | -0.093 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.24.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.gamma
 | -0.000 | -0.091 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.25.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.bias
 | -0.000 | -0.095 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.25.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.25.pwconv1.bias
 |  0.000 | -0.105 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.25.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.gamma
 |  0.000 | -0.082 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.26.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.bias
 | -0.000 | -0.102 |  0.100 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.26.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.26.pwconv1.bias
 |  0.000 | -0.093 |  0.109 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.26.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.gamma
 | -0.000 | -0.079 |  0.084 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.bias
 |  0.000 | -0.099 |  0.101 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.0.pwconv1.bias
 |  0.000 | -0.105 |  0.105 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.gamma
 | -0.000 | -0.088 |  0.086 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.bias
 |  0.000 | -0.098 |  0.109 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.1.pwconv1.bias
 |  0.000 | -0.102 |  0.103 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.gamma
 | -0.000 | -0.080 |  0.084 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.bias
 | -0.000 | -0.100 |  0.103 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.2.pwconv1.bias
 |  0.000 | -0.101 |  0.103 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.pwconv2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.norm.bias
 | -0.000 | -0.101 |  0.098 |  0.020 | torch.Size([2048, 1024]) || encoder.fc.layers.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_var
 |  0.000 | -0.104 |  0.106 |  0.020 | torch.Size([4096, 2048]) || encoder.fc.layers.4.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.4.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_var
 | -0.000 | -0.090 |  0.090 |  0.020 | torch.Size([63, 4096]) || encoder.fc.layers.8.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.8.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_var

24-04-05 14:13:24.673 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 14:13:24.687 : Number of train images: 165, iters: 83
24-04-05 14:13:30.271 : 
Networks name: Autoencoder
Params number: 98324797
Net structure:
Autoencoder(
  (encoder): Encoder(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (9): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (10): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (11): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (12): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (13): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (14): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (15): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (16): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (17): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (18): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (19): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (20): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (21): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (22): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (23): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (24): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (25): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (26): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc): ForwardPool(
      (layers): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SELU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=2048, out_features=4096, bias=True)
        (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): SELU()
        (7): Dropout(p=0.0, inplace=False)
        (8): Linear(in_features=4096, out_features=63, bias=True)
        (9): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): SELU()
        (11): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder): Decoder()
)

Networks name: Discriminator_UNet
Params number: 4375745
Net structure:
Discriminator_UNet(
  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

24-04-05 14:13:30.410 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.001 | -0.064 |  0.064 |  0.020 | torch.Size([128, 1, 4, 4]) || encoder.downsample_layers.0.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.bias
 |  0.000 | -0.088 |  0.087 |  0.020 | torch.Size([256, 128, 2, 2]) || encoder.downsample_layers.1.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.1.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.bias
 |  0.000 | -0.092 |  0.103 |  0.020 | torch.Size([512, 256, 2, 2]) || encoder.downsample_layers.2.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.2.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.bias
 |  0.000 | -0.096 |  0.098 |  0.020 | torch.Size([1024, 512, 2, 2]) || encoder.downsample_layers.3.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.downsample_layers.3.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.gamma
 | -0.000 | -0.072 |  0.067 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.bias
 | -0.000 | -0.088 |  0.081 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.0.pwconv1.bias
 |  0.000 | -0.077 |  0.084 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.gamma
 | -0.000 | -0.077 |  0.079 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.bias
 |  0.000 | -0.079 |  0.086 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.1.pwconv1.bias
 |  0.000 | -0.086 |  0.086 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.gamma
 |  0.000 | -0.069 |  0.070 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.bias
 |  0.000 | -0.088 |  0.084 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.2.pwconv1.bias
 |  0.000 | -0.085 |  0.081 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.gamma
 |  0.000 | -0.085 |  0.075 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.bias
 | -0.000 | -0.094 |  0.083 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.0.pwconv1.bias
 |  0.000 | -0.090 |  0.092 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.gamma
 |  0.000 | -0.081 |  0.076 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.bias
 | -0.000 | -0.094 |  0.081 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.1.pwconv1.bias
 | -0.000 | -0.093 |  0.090 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.gamma
 | -0.000 | -0.083 |  0.076 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.bias
 |  0.000 | -0.094 |  0.089 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.2.pwconv1.bias
 |  0.000 | -0.087 |  0.087 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.gamma
 | -0.000 | -0.086 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.bias
 |  0.000 | -0.091 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.0.pwconv1.bias
 |  0.000 | -0.109 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.gamma
 | -0.000 | -0.083 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.bias
 |  0.000 | -0.094 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.1.pwconv1.bias
 | -0.000 | -0.114 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.gamma
 | -0.000 | -0.077 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.bias
 |  0.000 | -0.101 |  0.091 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.2.pwconv1.bias
 | -0.000 | -0.094 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.gamma
 |  0.000 | -0.082 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.3.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.bias
 |  0.000 | -0.109 |  0.090 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.3.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.3.pwconv1.bias
 | -0.000 | -0.101 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.3.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.gamma
 |  0.000 | -0.082 |  0.090 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.4.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.bias
 |  0.000 | -0.098 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.4.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.4.pwconv1.bias
 | -0.000 | -0.099 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.4.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.gamma
 | -0.000 | -0.077 |  0.089 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.5.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.bias
 |  0.000 | -0.100 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.5.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.5.pwconv1.bias
 |  0.000 | -0.096 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.5.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.gamma
 |  0.000 | -0.075 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.6.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.bias
 | -0.000 | -0.090 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.6.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.6.pwconv1.bias
 |  0.000 | -0.094 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.6.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.gamma
 | -0.000 | -0.082 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.7.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.bias
 |  0.000 | -0.095 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.7.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.7.pwconv1.bias
 | -0.000 | -0.097 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.7.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.gamma
 |  0.000 | -0.079 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.8.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.bias
 |  0.000 | -0.093 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.8.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.8.pwconv1.bias
 | -0.000 | -0.092 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.8.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.gamma
 |  0.000 | -0.085 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.9.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.bias
 |  0.000 | -0.104 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.9.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.9.pwconv1.bias
 |  0.000 | -0.101 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.9.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.gamma
 | -0.000 | -0.084 |  0.075 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.10.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.bias
 |  0.000 | -0.100 |  0.105 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.10.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.10.pwconv1.bias
 | -0.000 | -0.093 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.10.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.gamma
 |  0.000 | -0.083 |  0.075 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.11.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.bias
 |  0.000 | -0.101 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.11.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.11.pwconv1.bias
 |  0.000 | -0.095 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.11.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.gamma
 |  0.000 | -0.081 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.12.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.bias
 |  0.000 | -0.098 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.12.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.12.pwconv1.bias
 | -0.000 | -0.096 |  0.108 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.12.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.gamma
 |  0.000 | -0.091 |  0.092 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.13.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.bias
 |  0.000 | -0.096 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.13.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.13.pwconv1.bias
 |  0.000 | -0.092 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.13.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.gamma
 | -0.000 | -0.083 |  0.089 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.14.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.bias
 | -0.000 | -0.101 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.14.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.14.pwconv1.bias
 | -0.000 | -0.094 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.14.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.gamma
 |  0.000 | -0.070 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.15.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.bias
 | -0.000 | -0.091 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.15.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.15.pwconv1.bias
 | -0.000 | -0.100 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.15.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.gamma
 | -0.000 | -0.089 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.16.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.bias
 |  0.000 | -0.101 |  0.109 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.16.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.16.pwconv1.bias
 | -0.000 | -0.106 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.16.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.gamma
 |  0.000 | -0.091 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.17.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.bias
 |  0.000 | -0.102 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.17.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.17.pwconv1.bias
 |  0.000 | -0.100 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.17.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.gamma
 |  0.000 | -0.079 |  0.082 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.18.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.bias
 | -0.000 | -0.089 |  0.111 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.18.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.18.pwconv1.bias
 | -0.000 | -0.098 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.18.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.gamma
 |  0.000 | -0.073 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.19.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.bias
 | -0.000 | -0.093 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.19.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.19.pwconv1.bias
 |  0.000 | -0.103 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.19.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.gamma
 | -0.000 | -0.076 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.20.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.bias
 |  0.000 | -0.102 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.20.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.20.pwconv1.bias
 | -0.000 | -0.097 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.20.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.gamma
 |  0.000 | -0.076 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.21.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.bias
 | -0.000 | -0.106 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.21.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.21.pwconv1.bias
 | -0.000 | -0.092 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.21.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.gamma
 | -0.000 | -0.079 |  0.090 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.22.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.bias
 | -0.000 | -0.093 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.22.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.22.pwconv1.bias
 |  0.000 | -0.091 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.22.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.gamma
 | -0.000 | -0.080 |  0.075 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.23.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.bias
 |  0.000 | -0.092 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.23.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.23.pwconv1.bias
 |  0.000 | -0.096 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.23.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.gamma
 | -0.000 | -0.076 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.24.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.bias
 |  0.000 | -0.096 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.24.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.24.pwconv1.bias
 | -0.000 | -0.101 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.24.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.gamma
 | -0.000 | -0.090 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.25.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.bias
 |  0.000 | -0.096 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.25.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.25.pwconv1.bias
 | -0.000 | -0.100 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.25.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.gamma
 | -0.000 | -0.087 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.26.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.bias
 | -0.000 | -0.095 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.26.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.26.pwconv1.bias
 |  0.000 | -0.092 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.26.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.gamma
 | -0.000 | -0.084 |  0.086 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.bias
 |  0.000 | -0.101 |  0.099 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.0.pwconv1.bias
 |  0.000 | -0.098 |  0.102 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.gamma
 |  0.000 | -0.081 |  0.091 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.bias
 |  0.000 | -0.099 |  0.102 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.1.pwconv1.bias
 | -0.000 | -0.111 |  0.109 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.gamma
 |  0.000 | -0.079 |  0.081 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.bias
 | -0.000 | -0.096 |  0.113 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.2.pwconv1.bias
 |  0.000 | -0.104 |  0.101 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.pwconv2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.norm.bias
 |  0.000 | -0.101 |  0.098 |  0.020 | torch.Size([2048, 1024]) || encoder.fc.layers.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_var
 | -0.000 | -0.100 |  0.103 |  0.020 | torch.Size([4096, 2048]) || encoder.fc.layers.4.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.4.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_var
 | -0.000 | -0.091 |  0.085 |  0.020 | torch.Size([63, 4096]) || encoder.fc.layers.8.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.8.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_var

24-04-05 14:21:59.011 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 14:22:06.067 : Number of train images: 165, iters: 83
24-04-05 14:22:13.573 : 
Networks name: Autoencoder
Params number: 98324797
Net structure:
Autoencoder(
  (encoder): Encoder(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (9): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (10): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (11): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (12): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (13): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (14): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (15): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (16): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (17): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (18): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (19): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (20): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (21): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (22): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (23): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (24): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (25): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (26): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc): ForwardPool(
      (layers): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SELU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=2048, out_features=4096, bias=True)
        (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): SELU()
        (7): Dropout(p=0.0, inplace=False)
        (8): Linear(in_features=4096, out_features=63, bias=True)
        (9): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): SELU()
        (11): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder): Decoder()
)

Networks name: Discriminator_UNet
Params number: 4375745
Net structure:
Discriminator_UNet(
  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

24-04-05 14:22:13.726 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.082 |  0.087 |  0.020 | torch.Size([128, 1, 4, 4]) || encoder.downsample_layers.0.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.bias
 |  0.000 | -0.087 |  0.089 |  0.020 | torch.Size([256, 128, 2, 2]) || encoder.downsample_layers.1.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.1.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.bias
 |  0.000 | -0.091 |  0.095 |  0.020 | torch.Size([512, 256, 2, 2]) || encoder.downsample_layers.2.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.2.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.bias
 | -0.000 | -0.107 |  0.109 |  0.020 | torch.Size([1024, 512, 2, 2]) || encoder.downsample_layers.3.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.downsample_layers.3.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.gamma
 | -0.000 | -0.070 |  0.070 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.bias
 | -0.000 | -0.083 |  0.089 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.0.pwconv1.bias
 | -0.000 | -0.095 |  0.082 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.gamma
 |  0.000 | -0.083 |  0.076 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.bias
 |  0.000 | -0.092 |  0.079 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.1.pwconv1.bias
 | -0.000 | -0.081 |  0.083 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.gamma
 |  0.000 | -0.071 |  0.077 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.bias
 |  0.000 | -0.081 |  0.089 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.2.pwconv1.bias
 | -0.000 | -0.078 |  0.096 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.gamma
 |  0.000 | -0.095 |  0.075 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.bias
 | -0.000 | -0.098 |  0.090 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.0.pwconv1.bias
 |  0.000 | -0.098 |  0.097 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.gamma
 | -0.000 | -0.076 |  0.082 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.bias
 | -0.000 | -0.089 |  0.088 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.1.pwconv1.bias
 |  0.000 | -0.101 |  0.091 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.gamma
 |  0.000 | -0.076 |  0.080 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.bias
 |  0.000 | -0.091 |  0.105 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.2.pwconv1.bias
 |  0.000 | -0.084 |  0.091 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.gamma
 |  0.000 | -0.087 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.bias
 | -0.000 | -0.103 |  0.105 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.0.pwconv1.bias
 | -0.000 | -0.100 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.gamma
 |  0.000 | -0.079 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.bias
 | -0.000 | -0.104 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.1.pwconv1.bias
 | -0.000 | -0.095 |  0.107 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.gamma
 |  0.000 | -0.086 |  0.082 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.bias
 |  0.000 | -0.094 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.2.pwconv1.bias
 | -0.000 | -0.098 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.gamma
 |  0.000 | -0.077 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.3.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.bias
 | -0.000 | -0.095 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.3.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.3.pwconv1.bias
 |  0.000 | -0.092 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.3.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.gamma
 | -0.000 | -0.079 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.4.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.bias
 | -0.000 | -0.096 |  0.100 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.4.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.4.pwconv1.bias
 |  0.000 | -0.099 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.4.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.gamma
 | -0.000 | -0.079 |  0.102 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.5.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.bias
 | -0.000 | -0.101 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.5.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.5.pwconv1.bias
 | -0.000 | -0.097 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.5.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.gamma
 |  0.000 | -0.077 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.6.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.bias
 |  0.000 | -0.106 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.6.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.6.pwconv1.bias
 |  0.000 | -0.099 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.6.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.gamma
 |  0.000 | -0.075 |  0.091 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.7.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.bias
 |  0.000 | -0.099 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.7.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.7.pwconv1.bias
 | -0.000 | -0.092 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.7.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.gamma
 |  0.000 | -0.074 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.8.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.bias
 |  0.000 | -0.098 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.8.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.8.pwconv1.bias
 |  0.000 | -0.103 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.8.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.gamma
 | -0.000 | -0.082 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.9.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.bias
 | -0.000 | -0.098 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.9.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.9.pwconv1.bias
 |  0.000 | -0.098 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.9.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.gamma
 |  0.000 | -0.085 |  0.093 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.10.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.bias
 |  0.000 | -0.094 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.10.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.10.pwconv1.bias
 |  0.000 | -0.098 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.10.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.gamma
 | -0.000 | -0.078 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.11.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.bias
 |  0.000 | -0.091 |  0.091 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.11.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.11.pwconv1.bias
 |  0.000 | -0.094 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.11.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.gamma
 | -0.000 | -0.075 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.12.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.bias
 | -0.000 | -0.092 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.12.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.12.pwconv1.bias
 |  0.000 | -0.098 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.12.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.gamma
 |  0.000 | -0.100 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.13.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.bias
 |  0.000 | -0.097 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.13.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.13.pwconv1.bias
 |  0.000 | -0.090 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.13.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.gamma
 | -0.000 | -0.090 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.14.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.bias
 |  0.000 | -0.099 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.14.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.14.pwconv1.bias
 |  0.000 | -0.104 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.14.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.gamma
 | -0.000 | -0.079 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.15.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.bias
 |  0.000 | -0.096 |  0.103 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.15.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.15.pwconv1.bias
 |  0.000 | -0.102 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.15.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.gamma
 |  0.000 | -0.076 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.16.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.bias
 |  0.000 | -0.108 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.16.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.16.pwconv1.bias
 | -0.000 | -0.102 |  0.106 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.16.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.gamma
 |  0.000 | -0.090 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.17.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.bias
 |  0.000 | -0.098 |  0.091 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.17.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.17.pwconv1.bias
 |  0.000 | -0.092 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.17.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.gamma
 | -0.000 | -0.085 |  0.095 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.18.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.bias
 |  0.000 | -0.095 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.18.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.18.pwconv1.bias
 |  0.000 | -0.102 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.18.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.gamma
 | -0.000 | -0.077 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.19.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.bias
 | -0.000 | -0.105 |  0.100 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.19.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.19.pwconv1.bias
 | -0.000 | -0.101 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.19.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.gamma
 | -0.000 | -0.076 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.20.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.bias
 | -0.000 | -0.095 |  0.103 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.20.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.20.pwconv1.bias
 |  0.000 | -0.098 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.20.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.gamma
 | -0.000 | -0.087 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.21.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.bias
 |  0.000 | -0.094 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.21.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.21.pwconv1.bias
 | -0.000 | -0.096 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.21.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.gamma
 |  0.000 | -0.082 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.22.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.bias
 | -0.000 | -0.090 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.22.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.22.pwconv1.bias
 | -0.000 | -0.094 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.22.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.gamma
 | -0.000 | -0.075 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.23.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.bias
 |  0.000 | -0.093 |  0.091 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.23.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.23.pwconv1.bias
 |  0.000 | -0.094 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.23.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.gamma
 | -0.000 | -0.082 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.24.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.bias
 | -0.000 | -0.101 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.24.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.24.pwconv1.bias
 |  0.000 | -0.096 |  0.110 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.24.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.gamma
 | -0.000 | -0.083 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.25.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.bias
 |  0.000 | -0.101 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.25.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.25.pwconv1.bias
 | -0.000 | -0.095 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.25.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.gamma
 |  0.000 | -0.090 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.26.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.bias
 |  0.000 | -0.097 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.26.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.26.pwconv1.bias
 | -0.000 | -0.105 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.26.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.gamma
 |  0.000 | -0.077 |  0.081 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.bias
 |  0.000 | -0.101 |  0.099 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.0.pwconv1.bias
 | -0.000 | -0.103 |  0.097 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.gamma
 |  0.000 | -0.086 |  0.092 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.bias
 | -0.000 | -0.102 |  0.099 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.1.pwconv1.bias
 |  0.000 | -0.106 |  0.102 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.gamma
 | -0.000 | -0.079 |  0.079 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.bias
 |  0.000 | -0.106 |  0.103 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.2.pwconv1.bias
 | -0.000 | -0.113 |  0.103 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.pwconv2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.norm.bias
 | -0.000 | -0.102 |  0.097 |  0.020 | torch.Size([2048, 1024]) || encoder.fc.layers.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_var
 | -0.000 | -0.103 |  0.106 |  0.020 | torch.Size([4096, 2048]) || encoder.fc.layers.4.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.4.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_var
 |  0.000 | -0.094 |  0.099 |  0.020 | torch.Size([63, 4096]) || encoder.fc.layers.8.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.8.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_var

24-04-05 14:27:06.828 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 14:27:06.863 : Number of train images: 165, iters: 83
24-04-05 14:27:12.804 : 
Networks name: Autoencoder
Params number: 98324797
Net structure:
Autoencoder(
  (encoder): Encoder(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (9): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (10): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (11): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (12): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (13): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (14): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (15): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (16): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (17): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (18): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (19): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (20): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (21): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (22): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (23): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (24): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (25): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (26): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc): ForwardPool(
      (layers): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SELU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=2048, out_features=4096, bias=True)
        (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): SELU()
        (7): Dropout(p=0.0, inplace=False)
        (8): Linear(in_features=4096, out_features=63, bias=True)
        (9): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): SELU()
        (11): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder): Decoder()
)

Networks name: Discriminator_UNet
Params number: 4375745
Net structure:
Discriminator_UNet(
  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

24-04-05 14:27:12.954 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.069 |  0.067 |  0.020 | torch.Size([128, 1, 4, 4]) || encoder.downsample_layers.0.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.bias
 |  0.000 | -0.086 |  0.088 |  0.020 | torch.Size([256, 128, 2, 2]) || encoder.downsample_layers.1.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.1.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.bias
 | -0.000 | -0.094 |  0.088 |  0.020 | torch.Size([512, 256, 2, 2]) || encoder.downsample_layers.2.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.2.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.bias
 | -0.000 | -0.099 |  0.097 |  0.020 | torch.Size([1024, 512, 2, 2]) || encoder.downsample_layers.3.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.downsample_layers.3.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.gamma
 |  0.000 | -0.070 |  0.093 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.bias
 |  0.000 | -0.084 |  0.091 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.0.pwconv1.bias
 | -0.000 | -0.090 |  0.081 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.gamma
 | -0.000 | -0.076 |  0.069 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.bias
 | -0.000 | -0.078 |  0.098 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.1.pwconv1.bias
 |  0.000 | -0.087 |  0.088 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.gamma
 | -0.000 | -0.070 |  0.069 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.bias
 |  0.000 | -0.088 |  0.089 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.2.pwconv1.bias
 | -0.000 | -0.091 |  0.078 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.gamma
 | -0.000 | -0.078 |  0.078 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.bias
 | -0.000 | -0.094 |  0.086 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.0.pwconv1.bias
 | -0.000 | -0.086 |  0.089 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.gamma
 | -0.000 | -0.076 |  0.070 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.bias
 |  0.000 | -0.095 |  0.087 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.1.pwconv1.bias
 |  0.000 | -0.089 |  0.088 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.gamma
 |  0.000 | -0.081 |  0.087 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.bias
 |  0.000 | -0.089 |  0.091 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.2.pwconv1.bias
 |  0.000 | -0.084 |  0.085 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.gamma
 | -0.000 | -0.080 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.bias
 | -0.000 | -0.101 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.0.pwconv1.bias
 |  0.000 | -0.092 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.gamma
 | -0.000 | -0.085 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.bias
 | -0.000 | -0.099 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.1.pwconv1.bias
 | -0.000 | -0.091 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.gamma
 |  0.000 | -0.078 |  0.092 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.bias
 | -0.000 | -0.099 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.2.pwconv1.bias
 | -0.000 | -0.096 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.gamma
 | -0.000 | -0.086 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.3.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.bias
 | -0.000 | -0.092 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.3.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.3.pwconv1.bias
 | -0.000 | -0.097 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.3.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.gamma
 |  0.000 | -0.080 |  0.092 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.4.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.bias
 |  0.000 | -0.089 |  0.100 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.4.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.4.pwconv1.bias
 | -0.000 | -0.097 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.4.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.gamma
 | -0.000 | -0.094 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.5.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.bias
 |  0.000 | -0.097 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.5.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.5.pwconv1.bias
 | -0.000 | -0.097 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.5.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.gamma
 |  0.000 | -0.092 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.6.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.bias
 |  0.000 | -0.093 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.6.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.6.pwconv1.bias
 |  0.000 | -0.104 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.6.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.gamma
 | -0.000 | -0.081 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.7.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.bias
 |  0.000 | -0.095 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.7.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.7.pwconv1.bias
 | -0.000 | -0.097 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.7.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.gamma
 |  0.000 | -0.087 |  0.082 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.8.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.bias
 |  0.000 | -0.094 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.8.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.8.pwconv1.bias
 |  0.000 | -0.103 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.8.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.gamma
 |  0.000 | -0.079 |  0.082 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.9.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.bias
 |  0.000 | -0.099 |  0.090 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.9.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.9.pwconv1.bias
 |  0.000 | -0.095 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.9.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.gamma
 | -0.000 | -0.081 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.10.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.bias
 |  0.000 | -0.100 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.10.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.10.pwconv1.bias
 |  0.000 | -0.094 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.10.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.gamma
 | -0.000 | -0.078 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.11.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.bias
 | -0.000 | -0.092 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.11.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.11.pwconv1.bias
 | -0.000 | -0.096 |  0.113 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.11.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.gamma
 | -0.000 | -0.083 |  0.082 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.12.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.bias
 | -0.000 | -0.100 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.12.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.12.pwconv1.bias
 | -0.000 | -0.094 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.12.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.gamma
 |  0.000 | -0.090 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.13.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.bias
 | -0.000 | -0.090 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.13.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.13.pwconv1.bias
 |  0.000 | -0.095 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.13.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.gamma
 | -0.000 | -0.087 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.14.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.bias
 | -0.000 | -0.094 |  0.099 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.14.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.14.pwconv1.bias
 | -0.000 | -0.095 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.14.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.gamma
 | -0.000 | -0.081 |  0.072 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.15.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.bias
 | -0.000 | -0.102 |  0.105 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.15.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.15.pwconv1.bias
 | -0.000 | -0.098 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.15.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.gamma
 |  0.000 | -0.089 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.16.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.bias
 | -0.000 | -0.106 |  0.088 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.16.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.16.pwconv1.bias
 |  0.000 | -0.091 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.16.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.gamma
 |  0.000 | -0.081 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.17.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.bias
 |  0.000 | -0.091 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.17.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.17.pwconv1.bias
 | -0.000 | -0.099 |  0.112 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.17.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.gamma
 | -0.000 | -0.079 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.18.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.bias
 |  0.000 | -0.098 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.18.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.18.pwconv1.bias
 |  0.000 | -0.097 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.18.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.gamma
 |  0.000 | -0.071 |  0.089 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.19.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.bias
 |  0.000 | -0.096 |  0.108 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.19.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.19.pwconv1.bias
 | -0.000 | -0.093 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.19.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.gamma
 |  0.000 | -0.075 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.20.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.bias
 | -0.000 | -0.092 |  0.104 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.20.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.20.pwconv1.bias
 |  0.000 | -0.095 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.20.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.gamma
 |  0.000 | -0.084 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.21.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.bias
 | -0.000 | -0.102 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.21.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.21.pwconv1.bias
 |  0.000 | -0.096 |  0.109 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.21.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.gamma
 |  0.000 | -0.083 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.22.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.bias
 |  0.000 | -0.095 |  0.104 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.22.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.22.pwconv1.bias
 |  0.000 | -0.092 |  0.089 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.22.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.gamma
 | -0.000 | -0.083 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.23.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.bias
 |  0.000 | -0.096 |  0.105 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.23.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.23.pwconv1.bias
 | -0.000 | -0.093 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.23.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.gamma
 | -0.000 | -0.080 |  0.075 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.24.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.bias
 | -0.000 | -0.104 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.24.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.24.pwconv1.bias
 |  0.000 | -0.096 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.24.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.gamma
 | -0.000 | -0.076 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.25.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.bias
 | -0.000 | -0.101 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.25.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.25.pwconv1.bias
 |  0.000 | -0.093 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.25.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.gamma
 | -0.000 | -0.076 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.26.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.bias
 |  0.000 | -0.092 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.26.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.26.pwconv1.bias
 |  0.000 | -0.098 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.26.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.gamma
 | -0.000 | -0.086 |  0.087 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.bias
 | -0.000 | -0.101 |  0.103 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.0.pwconv1.bias
 | -0.000 | -0.102 |  0.099 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.gamma
 |  0.000 | -0.081 |  0.094 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.bias
 | -0.000 | -0.107 |  0.099 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.1.pwconv1.bias
 | -0.000 | -0.106 |  0.102 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.gamma
 |  0.000 | -0.094 |  0.078 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.bias
 | -0.000 | -0.107 |  0.102 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.2.pwconv1.bias
 | -0.000 | -0.099 |  0.109 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.pwconv2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.norm.bias
 |  0.000 | -0.095 |  0.106 |  0.020 | torch.Size([2048, 1024]) || encoder.fc.layers.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_var
 | -0.000 | -0.114 |  0.111 |  0.020 | torch.Size([4096, 2048]) || encoder.fc.layers.4.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.4.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_var
 |  0.000 | -0.089 |  0.096 |  0.020 | torch.Size([63, 4096]) || encoder.fc.layers.8.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.8.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_var

24-04-05 16:45:07.545 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 16:45:32.289 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 16:45:32.355 : Number of train images: 165, iters: 83
24-04-05 16:45:39.275 : 
Networks name: Autoencoder
Params number: 98324797
Net structure:
Autoencoder(
  (encoder): Encoder(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (9): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (10): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (11): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (12): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (13): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (14): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (15): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (16): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (17): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (18): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (19): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (20): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (21): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (22): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (23): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (24): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (25): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (26): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc): ForwardPool(
      (layers): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SELU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=2048, out_features=4096, bias=True)
        (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): SELU()
        (7): Dropout(p=0.0, inplace=False)
        (8): Linear(in_features=4096, out_features=63, bias=True)
        (9): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): SELU()
        (11): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder): Decoder()
)

Networks name: Discriminator_UNet
Params number: 4375745
Net structure:
Discriminator_UNet(
  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

24-04-05 16:45:39.442 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.064 |  0.076 |  0.020 | torch.Size([128, 1, 4, 4]) || encoder.downsample_layers.0.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.bias
 | -0.000 | -0.084 |  0.088 |  0.020 | torch.Size([256, 128, 2, 2]) || encoder.downsample_layers.1.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.1.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.bias
 |  0.000 | -0.104 |  0.100 |  0.020 | torch.Size([512, 256, 2, 2]) || encoder.downsample_layers.2.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.2.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.bias
 | -0.000 | -0.100 |  0.099 |  0.020 | torch.Size([1024, 512, 2, 2]) || encoder.downsample_layers.3.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.downsample_layers.3.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.gamma
 | -0.000 | -0.076 |  0.079 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.bias
 |  0.000 | -0.087 |  0.085 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.0.pwconv1.bias
 |  0.000 | -0.083 |  0.083 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.gamma
 |  0.000 | -0.071 |  0.066 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.bias
 | -0.000 | -0.080 |  0.079 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.1.pwconv1.bias
 | -0.000 | -0.078 |  0.084 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.gamma
 |  0.001 | -0.073 |  0.083 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.bias
 |  0.000 | -0.089 |  0.090 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.2.pwconv1.bias
 |  0.000 | -0.081 |  0.084 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.gamma
 |  0.000 | -0.076 |  0.083 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.bias
 | -0.000 | -0.102 |  0.096 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.0.pwconv1.bias
 | -0.000 | -0.097 |  0.089 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.gamma
 | -0.000 | -0.089 |  0.082 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.bias
 |  0.000 | -0.088 |  0.089 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.1.pwconv1.bias
 | -0.000 | -0.087 |  0.088 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.gamma
 | -0.000 | -0.073 |  0.091 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.bias
 |  0.000 | -0.091 |  0.086 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.2.pwconv1.bias
 |  0.000 | -0.098 |  0.086 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.gamma
 | -0.000 | -0.078 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.bias
 | -0.000 | -0.103 |  0.104 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.0.pwconv1.bias
 | -0.000 | -0.098 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.gamma
 |  0.000 | -0.078 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.bias
 |  0.000 | -0.106 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.1.pwconv1.bias
 | -0.000 | -0.096 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.gamma
 | -0.000 | -0.077 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.bias
 |  0.000 | -0.092 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.2.pwconv1.bias
 |  0.000 | -0.095 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.gamma
 |  0.000 | -0.087 |  0.096 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.3.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.bias
 | -0.000 | -0.094 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.3.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.3.pwconv1.bias
 | -0.000 | -0.101 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.3.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.gamma
 | -0.000 | -0.081 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.4.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.bias
 |  0.000 | -0.103 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.4.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.4.pwconv1.bias
 |  0.000 | -0.099 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.4.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.gamma
 | -0.000 | -0.082 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.5.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.bias
 |  0.000 | -0.101 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.5.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.5.pwconv1.bias
 |  0.000 | -0.111 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.5.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.gamma
 | -0.000 | -0.088 |  0.092 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.6.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.bias
 | -0.000 | -0.097 |  0.110 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.6.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.6.pwconv1.bias
 | -0.000 | -0.094 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.6.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.gamma
 | -0.000 | -0.073 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.7.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.bias
 | -0.000 | -0.092 |  0.104 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.7.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.7.pwconv1.bias
 |  0.000 | -0.100 |  0.090 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.7.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.gamma
 |  0.000 | -0.080 |  0.093 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.8.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.bias
 | -0.000 | -0.092 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.8.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.8.pwconv1.bias
 |  0.000 | -0.095 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.8.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.gamma
 |  0.000 | -0.077 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.9.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.bias
 |  0.000 | -0.091 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.9.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.9.pwconv1.bias
 |  0.000 | -0.099 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.9.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.gamma
 |  0.000 | -0.073 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.10.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.bias
 |  0.000 | -0.103 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.10.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.10.pwconv1.bias
 | -0.000 | -0.091 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.10.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.gamma
 |  0.000 | -0.079 |  0.094 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.11.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.bias
 | -0.000 | -0.093 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.11.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.11.pwconv1.bias
 |  0.000 | -0.104 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.11.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.gamma
 | -0.000 | -0.081 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.12.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.bias
 |  0.000 | -0.105 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.12.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.12.pwconv1.bias
 |  0.000 | -0.094 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.12.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.gamma
 |  0.000 | -0.087 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.13.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.bias
 |  0.000 | -0.091 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.13.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.13.pwconv1.bias
 |  0.000 | -0.094 |  0.102 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.13.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.gamma
 | -0.000 | -0.086 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.14.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.bias
 |  0.000 | -0.097 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.14.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.14.pwconv1.bias
 |  0.000 | -0.099 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.14.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.gamma
 | -0.000 | -0.071 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.15.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.bias
 | -0.000 | -0.100 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.15.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.15.pwconv1.bias
 |  0.000 | -0.104 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.15.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.gamma
 | -0.000 | -0.076 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.16.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.bias
 | -0.000 | -0.100 |  0.091 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.16.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.16.pwconv1.bias
 |  0.000 | -0.091 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.16.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.gamma
 | -0.000 | -0.077 |  0.082 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.17.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.bias
 | -0.000 | -0.099 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.17.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.17.pwconv1.bias
 | -0.000 | -0.095 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.17.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.gamma
 |  0.000 | -0.085 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.18.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.bias
 | -0.000 | -0.092 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.18.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.18.pwconv1.bias
 | -0.000 | -0.098 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.18.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.gamma
 | -0.000 | -0.074 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.19.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.bias
 | -0.000 | -0.099 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.19.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.19.pwconv1.bias
 | -0.000 | -0.095 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.19.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.gamma
 |  0.000 | -0.077 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.20.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.bias
 | -0.000 | -0.102 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.20.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.20.pwconv1.bias
 |  0.000 | -0.096 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.20.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.gamma
 | -0.000 | -0.078 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.21.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.bias
 | -0.000 | -0.090 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.21.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.21.pwconv1.bias
 |  0.000 | -0.091 |  0.092 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.21.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.gamma
 |  0.000 | -0.075 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.22.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.bias
 |  0.000 | -0.095 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.22.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.22.pwconv1.bias
 |  0.000 | -0.091 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.22.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.gamma
 |  0.000 | -0.081 |  0.092 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.23.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.bias
 |  0.000 | -0.097 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.23.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.23.pwconv1.bias
 |  0.000 | -0.105 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.23.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.gamma
 |  0.000 | -0.081 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.24.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.bias
 | -0.000 | -0.097 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.24.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.24.pwconv1.bias
 |  0.000 | -0.097 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.24.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.gamma
 | -0.000 | -0.102 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.25.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.bias
 | -0.000 | -0.098 |  0.106 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.25.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.25.pwconv1.bias
 | -0.000 | -0.099 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.25.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.gamma
 |  0.000 | -0.080 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.26.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.bias
 | -0.000 | -0.093 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.26.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.26.pwconv1.bias
 |  0.000 | -0.101 |  0.090 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.26.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.gamma
 |  0.000 | -0.081 |  0.081 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.bias
 | -0.000 | -0.103 |  0.099 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.0.pwconv1.bias
 |  0.000 | -0.100 |  0.106 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.gamma
 |  0.000 | -0.083 |  0.084 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.bias
 | -0.000 | -0.107 |  0.106 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.1.pwconv1.bias
 |  0.000 | -0.097 |  0.102 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.gamma
 | -0.000 | -0.082 |  0.081 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.bias
 | -0.000 | -0.102 |  0.105 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.2.pwconv1.bias
 | -0.000 | -0.099 |  0.101 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.pwconv2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.norm.bias
 | -0.000 | -0.100 |  0.108 |  0.020 | torch.Size([2048, 1024]) || encoder.fc.layers.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_var
 |  0.000 | -0.107 |  0.101 |  0.020 | torch.Size([4096, 2048]) || encoder.fc.layers.4.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.4.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_var
 | -0.000 | -0.091 |  0.096 |  0.020 | torch.Size([63, 4096]) || encoder.fc.layers.8.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.8.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_var

24-04-05 16:48:24.599 :   task: convsmoe_gan
  model: gan
  gpu_ids: [0]
  scale: 4
  n_channels: 3
  sigma: [0, 50]
  sigma_test: 15
  merge_bn: False
  merge_bn_startpoint: 400000
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netD: None
    pretrained_netE: None
    task: superresolution/convsmoe_gan
    log: superresolution/convsmoe_gan
    options: superresolution/convsmoe_gan/options
    models: superresolution/convsmoe_gan/models
    images: superresolution/convsmoe_gan/images
    pretrained_optimizerG: None
    pretrained_optimizerD: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr-lf
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_train/SR_5x5_4x/Stanford_Gantry
      dataroot_L: None
      H_size: 256
      dataloader_shuffle: True
      dataloader_num_workers: 8
      dataloader_batch_size: 2
      phw: 32
      stride: 2
      phase: train
      scale: 4
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: /home/ozkan/works/diff-smoe/LFT/data_for_test/SR_5x5_4x
      dataroot_L: None
      H_size: 256
      dataloader_num_workers: 8
      dataloader_batch_size: 1
      phw: 32
      stride: 2
      phase: test
      scale: 4
      n_channels: 3
    ]
  ]
  netG:[
    net_type: conv_smoe
    in_channels: 1
    kernel: 9
    num_mixtures: 9
    depths: [3, 3, 27, 3]
    dims: [128, 256, 512, 1024]
    phw: 32
    stride: 2
    dropout: 0.01
    scale_factor: 4
    sharpening_factor: 1.0
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
    scale: 4
  ]
  netD:[
    net_type: discriminator_unet
    in_nc: 1
    base_nc: 64
    act_mode: BL
    n_layers: 3
    norm_type: batchspectral
    init_type: normal
    init_bn_type: uniform
    init_gain: 0.2
  ]
  train:[
    G_lossfn_type: l2sum
    G_lossfn_weight: 0.01
    F_lossfn_type: l1
    F_lossfn_weight: 1
    F_feature_layer: 34
    F_weights: 1.0
    F_use_input_norm: True
    F_use_range_norm: False
    gan_type: gan
    D_lossfn_weight: 0.005
    E_decay: 0.999
    D_init_iters: 0
    G_optimizer_type: adam
    G_optimizer_lr: 1e-05
    G_optimizer_wd: 0
    D_optimizer_type: adam
    D_optimizer_lr: 1e-05
    D_optimizer_wd: 0
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    G_scheduler_gamma: 0.5
    G_optimizer_reuse: False
    D_scheduler_type: MultiStepLR
    D_scheduler_milestones: [200000, 800000, 1200000, 2000000]
    D_scheduler_gamma: 0.5
    D_optimizer_reuse: False
    G_param_strict: True
    D_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/train_convsmoe_gan.json
  is_train: True
  find_unused_parameters: True
  use_static_graph: False
  dist: False
  num_gpu: 1
  rank: 0
  world_size: 1

24-04-05 16:48:24.629 : Number of train images: 165, iters: 83
24-04-05 16:48:31.406 : 
Networks name: Autoencoder
Params number: 98324797
Net structure:
Autoencoder(
  (encoder): Encoder(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=512, out_features=128, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (9): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (10): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (11): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (12): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (13): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (14): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (15): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (16): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (17): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (18): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (19): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (20): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (21): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (22): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (23): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (24): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (25): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
        (26): Block(
          (dwconv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=2048, out_features=512, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc): ForwardPool(
      (layers): Sequential(
        (0): Linear(in_features=1024, out_features=2048, bias=True)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): SELU()
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=2048, out_features=4096, bias=True)
        (5): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): SELU()
        (7): Dropout(p=0.0, inplace=False)
        (8): Linear(in_features=4096, out_features=63, bias=True)
        (9): BatchNorm1d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): SELU()
        (11): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder): Decoder()
)

Networks name: Discriminator_UNet
Params number: 4375745
Net structure:
Discriminator_UNet(
  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
  (conv4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)

24-04-05 16:48:31.542 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.000 | -0.076 |  0.079 |  0.020 | torch.Size([128, 1, 4, 4]) || encoder.downsample_layers.0.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.0.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.downsample_layers.1.0.bias
 | -0.000 | -0.086 |  0.083 |  0.020 | torch.Size([256, 128, 2, 2]) || encoder.downsample_layers.1.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.1.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.downsample_layers.2.0.bias
 |  0.000 | -0.094 |  0.087 |  0.020 | torch.Size([512, 256, 2, 2]) || encoder.downsample_layers.2.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.2.1.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.downsample_layers.3.0.bias
 |  0.000 | -0.100 |  0.105 |  0.020 | torch.Size([1024, 512, 2, 2]) || encoder.downsample_layers.3.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.downsample_layers.3.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.gamma
 | -0.000 | -0.069 |  0.082 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.norm.bias
 |  0.000 | -0.082 |  0.102 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.0.pwconv1.bias
 | -0.000 | -0.082 |  0.085 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.gamma
 | -0.000 | -0.074 |  0.074 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.norm.bias
 | -0.000 | -0.085 |  0.079 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.1.pwconv1.bias
 | -0.000 | -0.084 |  0.079 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.gamma
 |  0.000 | -0.073 |  0.082 |  0.020 | torch.Size([128, 1, 7, 7]) || encoder.stages.0.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.norm.bias
 | -0.000 | -0.087 |  0.087 |  0.020 | torch.Size([512, 128]) || encoder.stages.0.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.0.2.pwconv1.bias
 |  0.000 | -0.089 |  0.083 |  0.020 | torch.Size([128, 512]) || encoder.stages.0.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([128]) || encoder.stages.0.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.gamma
 | -0.000 | -0.073 |  0.089 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.norm.bias
 | -0.000 | -0.081 |  0.101 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.0.pwconv1.bias
 | -0.000 | -0.090 |  0.092 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.gamma
 | -0.000 | -0.074 |  0.081 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.norm.bias
 |  0.000 | -0.088 |  0.101 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.1.pwconv1.bias
 | -0.000 | -0.092 |  0.101 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.gamma
 | -0.000 | -0.081 |  0.075 |  0.020 | torch.Size([256, 1, 7, 7]) || encoder.stages.1.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.norm.bias
 |  0.000 | -0.094 |  0.090 |  0.020 | torch.Size([1024, 256]) || encoder.stages.1.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.1.2.pwconv1.bias
 | -0.000 | -0.096 |  0.092 |  0.020 | torch.Size([256, 1024]) || encoder.stages.1.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([256]) || encoder.stages.1.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.gamma
 | -0.000 | -0.081 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.norm.bias
 |  0.000 | -0.091 |  0.101 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.0.pwconv1.bias
 |  0.000 | -0.099 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.gamma
 |  0.000 | -0.087 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.norm.bias
 | -0.000 | -0.100 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.1.pwconv1.bias
 | -0.000 | -0.098 |  0.112 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.gamma
 |  0.000 | -0.088 |  0.096 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.norm.bias
 |  0.000 | -0.097 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.2.pwconv1.bias
 | -0.000 | -0.094 |  0.096 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.2.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.gamma
 |  0.000 | -0.074 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.3.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.norm.bias
 | -0.000 | -0.092 |  0.102 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.3.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.3.pwconv1.bias
 | -0.000 | -0.090 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.3.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.3.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.gamma
 | -0.000 | -0.087 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.4.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.norm.bias
 | -0.000 | -0.098 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.4.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.4.pwconv1.bias
 |  0.000 | -0.097 |  0.095 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.4.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.4.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.gamma
 | -0.000 | -0.079 |  0.089 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.5.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.norm.bias
 | -0.000 | -0.093 |  0.105 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.5.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.5.pwconv1.bias
 | -0.000 | -0.095 |  0.107 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.5.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.5.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.gamma
 | -0.000 | -0.075 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.6.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.norm.bias
 | -0.000 | -0.101 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.6.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.6.pwconv1.bias
 | -0.000 | -0.095 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.6.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.6.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.gamma
 |  0.000 | -0.083 |  0.078 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.7.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.norm.bias
 | -0.000 | -0.094 |  0.096 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.7.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.7.pwconv1.bias
 |  0.000 | -0.098 |  0.108 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.7.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.7.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.gamma
 | -0.000 | -0.084 |  0.087 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.8.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.norm.bias
 |  0.000 | -0.096 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.8.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.8.pwconv1.bias
 | -0.000 | -0.103 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.8.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.8.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.gamma
 | -0.000 | -0.080 |  0.075 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.9.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.norm.bias
 |  0.000 | -0.099 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.9.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.9.pwconv1.bias
 |  0.000 | -0.099 |  0.098 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.9.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.9.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.gamma
 |  0.000 | -0.076 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.10.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.norm.bias
 | -0.000 | -0.107 |  0.104 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.10.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.10.pwconv1.bias
 |  0.000 | -0.107 |  0.099 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.10.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.10.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.gamma
 | -0.000 | -0.079 |  0.074 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.11.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.norm.bias
 | -0.000 | -0.094 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.11.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.11.pwconv1.bias
 | -0.000 | -0.097 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.11.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.11.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.gamma
 |  0.000 | -0.081 |  0.086 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.12.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.norm.bias
 | -0.000 | -0.100 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.12.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.12.pwconv1.bias
 | -0.000 | -0.092 |  0.090 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.12.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.12.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.gamma
 | -0.000 | -0.075 |  0.090 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.13.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.norm.bias
 |  0.000 | -0.098 |  0.091 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.13.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.13.pwconv1.bias
 | -0.000 | -0.097 |  0.103 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.13.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.13.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.gamma
 |  0.000 | -0.080 |  0.085 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.14.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.norm.bias
 | -0.000 | -0.096 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.14.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.14.pwconv1.bias
 |  0.000 | -0.094 |  0.101 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.14.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.14.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.gamma
 | -0.000 | -0.083 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.15.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.norm.bias
 | -0.000 | -0.101 |  0.092 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.15.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.15.pwconv1.bias
 | -0.000 | -0.102 |  0.104 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.15.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.15.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.gamma
 | -0.000 | -0.079 |  0.076 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.16.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.norm.bias
 | -0.000 | -0.103 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.16.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.16.pwconv1.bias
 | -0.000 | -0.093 |  0.094 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.16.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.16.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.gamma
 | -0.000 | -0.084 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.17.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.norm.bias
 |  0.000 | -0.098 |  0.095 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.17.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.17.pwconv1.bias
 | -0.000 | -0.096 |  0.100 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.17.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.17.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.gamma
 | -0.000 | -0.077 |  0.083 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.18.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.norm.bias
 | -0.000 | -0.095 |  0.103 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.18.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.18.pwconv1.bias
 |  0.000 | -0.094 |  0.097 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.18.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.18.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.gamma
 | -0.000 | -0.088 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.19.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.norm.bias
 | -0.000 | -0.095 |  0.089 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.19.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.19.pwconv1.bias
 | -0.000 | -0.103 |  0.107 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.19.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.19.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.gamma
 | -0.000 | -0.086 |  0.080 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.20.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.norm.bias
 |  0.000 | -0.093 |  0.098 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.20.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.20.pwconv1.bias
 |  0.000 | -0.099 |  0.106 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.20.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.20.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.gamma
 |  0.000 | -0.091 |  0.088 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.21.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.norm.bias
 |  0.000 | -0.093 |  0.100 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.21.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.21.pwconv1.bias
 | -0.000 | -0.092 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.21.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.21.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.gamma
 | -0.000 | -0.078 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.22.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.norm.bias
 | -0.000 | -0.096 |  0.094 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.22.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.22.pwconv1.bias
 | -0.000 | -0.115 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.22.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.22.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.gamma
 |  0.000 | -0.077 |  0.081 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.23.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.norm.bias
 | -0.000 | -0.095 |  0.103 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.23.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.23.pwconv1.bias
 | -0.000 | -0.093 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.23.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.23.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.gamma
 | -0.000 | -0.090 |  0.077 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.24.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.norm.bias
 |  0.000 | -0.097 |  0.097 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.24.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.24.pwconv1.bias
 | -0.000 | -0.098 |  0.093 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.24.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.24.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.gamma
 |  0.000 | -0.078 |  0.079 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.25.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.norm.bias
 | -0.000 | -0.095 |  0.104 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.25.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.25.pwconv1.bias
 |  0.000 | -0.098 |  0.110 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.25.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.25.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.gamma
 |  0.000 | -0.075 |  0.084 |  0.020 | torch.Size([512, 1, 7, 7]) || encoder.stages.2.26.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.norm.bias
 |  0.000 | -0.096 |  0.093 |  0.020 | torch.Size([2048, 512]) || encoder.stages.2.26.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.stages.2.26.pwconv1.bias
 | -0.000 | -0.094 |  0.091 |  0.020 | torch.Size([512, 2048]) || encoder.stages.2.26.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([512]) || encoder.stages.2.26.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.gamma
 |  0.000 | -0.084 |  0.079 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.0.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.norm.bias
 | -0.000 | -0.109 |  0.097 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.0.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.0.pwconv1.bias
 |  0.000 | -0.107 |  0.105 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.0.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.0.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.gamma
 | -0.000 | -0.078 |  0.090 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.1.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.norm.bias
 |  0.000 | -0.111 |  0.103 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.1.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.1.pwconv1.bias
 | -0.000 | -0.100 |  0.099 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.1.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.1.pwconv2.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.gamma
 | -0.000 | -0.082 |  0.095 |  0.020 | torch.Size([1024, 1, 7, 7]) || encoder.stages.3.2.dwconv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.dwconv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.norm.bias
 | -0.000 | -0.100 |  0.105 |  0.020 | torch.Size([4096, 1024]) || encoder.stages.3.2.pwconv1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.stages.3.2.pwconv1.bias
 |  0.000 | -0.106 |  0.107 |  0.020 | torch.Size([1024, 4096]) || encoder.stages.3.2.pwconv2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.stages.3.2.pwconv2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([1024]) || encoder.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([1024]) || encoder.norm.bias
 |  0.000 | -0.097 |  0.103 |  0.020 | torch.Size([2048, 1024]) || encoder.fc.layers.0.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.0.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([2048]) || encoder.fc.layers.1.running_var
 | -0.000 | -0.097 |  0.109 |  0.020 | torch.Size([4096, 2048]) || encoder.fc.layers.4.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.4.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([4096]) || encoder.fc.layers.5.running_var
 |  0.000 | -0.090 |  0.090 |  0.020 | torch.Size([63, 4096]) || encoder.fc.layers.8.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.8.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.bias
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_mean
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([63]) || encoder.fc.layers.9.running_var

