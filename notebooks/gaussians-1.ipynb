{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "from jaxtyping import Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/pytorch3d/blob/main/pytorch3d/transforms/rotation_conversions.py\n",
    "def quaternion_to_matrix(\n",
    "    quaternions: Float[Tensor, \"*batch 4\"],\n",
    "    eps: float = 1e-8,\n",
    ") -> Float[Tensor, \"*batch 3 3\"]:\n",
    "    # Order changed to match scipy format!\n",
    "    i, j, k, r = torch.unbind(quaternions, dim=-1)\n",
    "    two_s = 2 / ((quaternions * quaternions).sum(dim=-1) + eps)\n",
    "\n",
    "    o = torch.stack(\n",
    "        (\n",
    "            1 - two_s * (j * j + k * k),\n",
    "            two_s * (i * j - k * r),\n",
    "            two_s * (i * k + j * r),\n",
    "            two_s * (i * j + k * r),\n",
    "            1 - two_s * (i * i + k * k),\n",
    "            two_s * (j * k - i * r),\n",
    "            two_s * (i * k - j * r),\n",
    "            two_s * (j * k + i * r),\n",
    "            1 - two_s * (i * i + j * j),\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return rearrange(o, \"... (i j) -> ... i j\", i=3, j=3)\n",
    "\n",
    "\n",
    "def build_covariance(\n",
    "    scale: Float[Tensor, \"*#batch 3\"],\n",
    "    rotation_xyzw: Float[Tensor, \"*#batch 4\"],\n",
    ") -> Float[Tensor, \"*batch 3 3\"]:\n",
    "    scale = scale.diag_embed()\n",
    "    rotation = quaternion_to_matrix(rotation_xyzw)\n",
    "    return (\n",
    "        rotation\n",
    "        @ scale\n",
    "        @ rearrange(scale, \"... i j -> ... j i\")\n",
    "        @ rearrange(rotation, \"... i j -> ... j i\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      "tensor([[[ 9.,  0.,  0.],\n",
      "         [ 0.,  4.,  0.],\n",
      "         [ 0.,  0., 16.]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "scale_factors = torch.tensor([[2.0, 3.0, 4.0]])  # Shape: [1, 3]\n",
    "\n",
    "# Define a quaternion for rotation (batch size of 1)\n",
    "# Quaternion format: [i, j, k, r] where r is the real part\n",
    "quaternion = torch.tensor([[0.0, 0.0, 0.707, 0.707]])  # Shape: [1, 4]\n",
    "\n",
    "\n",
    "covariance_matrix = build_covariance(scale_factors, quaternion)\n",
    "\n",
    "print(\"Covariance Matrix:\")\n",
    "print(covariance_matrix)\n",
    "print(covariance_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu shape: torch.Size([6, 9, 2])\n",
      "cov_matrix shape: torch.Size([6, 9, 2, 2])\n",
      "w shape: torch.Size([6, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Gaussians:\n",
    "    mu: Tensor\n",
    "    cov_matrix: Tensor\n",
    "    w: Tensor\n",
    "\n",
    "def quat_to_2d_mat(\n",
    "    Q: Tensor,\n",
    "    eps: float = 1e-8,\n",
    ") -> Tensor:\n",
    "    x, w = torch.unbind(Q, dim=-1)\n",
    "    s2 = 2 / ((Q * Q).sum(dim=-1) + eps)\n",
    "\n",
    "    M = torch.stack(\n",
    "        (\n",
    "            1 - s2 * (x * x),\n",
    "            s2 * (w * x),\n",
    "            -s2 * (w * x),\n",
    "            1 - s2 * (x * x),\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return rearrange(M, \"... (i j) -> ... i j\", i=2, j=2)\n",
    "\n",
    "def ang_to_rot_mat(\n",
    "    theta: Tensor,\n",
    "    eps: float = 1e-8,\n",
    ") -> Tensor:\n",
    "    theta = torch.unbind(theta, dim=-1)[0]\n",
    "    \n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    \n",
    "    R = torch.stack(\n",
    "        (\n",
    "            cos_theta,\n",
    "            -sin_theta,\n",
    "            sin_theta,\n",
    "            cos_theta\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return rearrange(R, \"... (i j) -> ... i j\", i=2, j=2)\n",
    "\n",
    "\n",
    "def cov_mat_2d(\n",
    "    scale: Tensor,\n",
    "    theta: Tensor,\n",
    "    epsilon: float = 1e-8\n",
    ") -> Tensor:\n",
    "    \n",
    "    \n",
    "    scale_mat = torch.diag_embed(torch.tril(scale + epsilon))\n",
    "    \n",
    "    R = ang_to_rot_mat(theta)\n",
    "    \n",
    "    cov_matrix = R @ scale_mat @ rearrange(scale_mat, \"... i j -> ... j i\") @ rearrange(R, \"... i j -> ... j i\")\n",
    "    \n",
    "    return cov_matrix\n",
    "\n",
    "def extract_params(p, k, alpha) -> Gaussians:\n",
    "    mu_x = p[:, :, :k].reshape(-1, k, 1)\n",
    "    mu_y = p[:, :, k:2 * k].reshape(-1, k, 1)\n",
    "    mu = torch.cat((mu_x, mu_y), 2).view(-1, k, 2)\n",
    "\n",
    "    scale_idx = 3 * k\n",
    "    scale = p[:, :, scale_idx:scale_idx + 2 * k].reshape(-1, k, 2)\n",
    "\n",
    "    rot_idx = scale_idx + 2 * k\n",
    "    theta = p[:, :, rot_idx:rot_idx + 2 * k].reshape(-1, k, 2)\n",
    "\n",
    "    cov_matrix = cov_mat_2d(scale, theta)\n",
    "    cov_matrix = torch.mul(cov_matrix, alpha)\n",
    "\n",
    "    w = p[:, :, 2 * k:3 * k].reshape(-1, k)\n",
    "\n",
    "    return Gaussians(mu, cov_matrix, w)\n",
    "\n",
    "batch_size = 2\n",
    "color = 3\n",
    "num_kernels = 9\n",
    "alpha = 1.0\n",
    "p = torch.randn(batch_size, color, 63)\n",
    "\n",
    "gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "print(\"mu shape:\", gaussians.mu.shape)  # Expected: [27, 9, 2]\n",
    "print(\"cov_matrix shape:\", gaussians.cov_matrix.shape)  # Expected: [27, 9, 2, 2]\n",
    "print(\"w shape:\", gaussians.w.shape)  # Expected: [27, 9]\n",
    "# print(\"Q shape:\", gaussians.Q.shape)  # Expected: [27, 9, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.2298), tensor(4.4037))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussians.cov_matrix.min(), gaussians.cov_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu shape: torch.Size([1, 3, 1, 2])\n",
      "cov_matrix shape: torch.Size([1, 3, 1, 2, 2])\n",
      "w shape: torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Gaussians:\n",
    "    mu: Tensor\n",
    "    cov_matrix: Tensor\n",
    "    w: Tensor\n",
    "\n",
    "def ang_to_rot_mat(theta: Tensor) -> Tensor:\n",
    "    cos_theta = torch.cos(theta).unsqueeze(-1)\n",
    "    sin_theta = torch.sin(theta).unsqueeze(-1)\n",
    "    R = torch.cat([cos_theta, -sin_theta, sin_theta, cos_theta], dim=-1)\n",
    "    return R.view(*theta.shape, 2, 2)\n",
    "\n",
    "def cov_mat_2d(scale: Tensor, theta: Tensor, epsilon: float = 1e-8) -> Tensor:\n",
    "    scale_mat = torch.diag_embed(scale + epsilon)\n",
    "    R = ang_to_rot_mat(theta)\n",
    "    cov_matrix = R @ scale_mat @ scale_mat.transpose(-2, -1) @ R.transpose(-2, -1)\n",
    "    return cov_matrix\n",
    "\n",
    "def extract_params(p: Tensor, k: int, alpha: float) -> Gaussians:\n",
    "    mu_x = p[:, :, :k].reshape(-1, color, k, 1)\n",
    "    mu_y = p[:, :, k:2*k].reshape(-1, color, k, 1)\n",
    "    mu = torch.cat((mu_x, mu_y), -1).view(-1, color, k, 2)\n",
    "\n",
    "    scale_idx = 3 * k\n",
    "    scale = p[:, :, scale_idx:scale_idx + 2*k].reshape(-1, color, k, 2)\n",
    "\n",
    "    rot_idx = scale_idx + 2 * k\n",
    "    theta = p[:, :, rot_idx:rot_idx + k].reshape(-1, color, k)\n",
    "\n",
    "    cov_matrix = cov_mat_2d(scale, theta)\n",
    "    cov_matrix = torch.mul(cov_matrix, alpha)\n",
    "\n",
    "    w = p[:, :, 2*k:3*k].reshape(-1, color, k)\n",
    "\n",
    "    return Gaussians(mu, cov_matrix, w)\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "color = 3\n",
    "num_kernels = 1\n",
    "alpha = 1.0\n",
    "p = torch.randn(batch_size, color, 63)  \n",
    "\n",
    "gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "print(\"mu shape:\", gaussians.mu.shape)  # Expected: [27, 3, 9, 2]\n",
    "print(\"cov_matrix shape:\", gaussians.cov_matrix.shape)  # Expected: [27, 3, 9, 2, 2]\n",
    "print(\"w shape:\", gaussians.w.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1170), tensor(3.9083))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussians.cov_matrix.min(), gaussians.cov_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cov_mat_2d(scale: Tensor, theta: Tensor, epsilon: float = 1e-8) -> Tensor:\n",
    "#     scale_mat = torch.diag_embed(scale + epsilon)\n",
    "#     R = ang_to_rot_mat(theta)\n",
    "#     cov_matrix = R @ scale_mat @ R.transpose(-2, -1)\n",
    "#     return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix Test:\n",
      " tensor([[[[[0.9704, 0.1460],\n",
      "           [0.1460, 0.2796]]]]])\n"
     ]
    }
   ],
   "source": [
    "theta_test = torch.tensor([[[0.2]]])  # Simple angle in radians\n",
    "scale_test = torch.tensor([[[1.0, 0.5]]])  # Simple scale\n",
    "\n",
    "cov_matrix_test = cov_mat_2d(scale_test, theta_test)\n",
    "print(\"Covariance Matrix Test:\\n\", cov_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def grid_f(height, width):\n",
    "#     xx = torch.linspace(0.0, 1.0, width)\n",
    "#     yy = torch.linspace(0.0, 1.0, height)\n",
    "#     grid_x, grid_y = torch.meshgrid(xx, yy, indexing=\"ij\")\n",
    "#     grid = torch.stack((grid_x, grid_y), 2).float()\n",
    "#     return grid.reshape(height * width, 2)\n",
    "\n",
    "# def forward(height, width, num_kernels, alpha, p):\n",
    "#     gaussians = extract_params(p, num_kernels, alpha)\n",
    "#     mu = gaussians.mu\n",
    "#     cov_matrix = gaussians.cov_matrix\n",
    "#     w = gaussians.w\n",
    "#     grid = grid_f(height, width).to(p.device)\n",
    "#     grid = grid.expand(mu.shape[0], mu.shape[1], -1, -1)\n",
    "#     x = grid.unsqueeze(2)\n",
    "#     mu = mu.unsqueeze(3)\n",
    "#     x_sub_mu = (x - mu).unsqueeze(-1)\n",
    "\n",
    "#     # Broadcast the cov_matrix for each spatial location\n",
    "#     cov_matrix_inv = torch.linalg.inv(cov_matrix)\n",
    "#     cov_matrix_inv_expanded = cov_matrix_inv.unsqueeze(2).expand(-1, -1, height*width, -1, -1)\n",
    "\n",
    "#     x_sub_mu_t = x_sub_mu.transpose(-1, -2)\n",
    "#     mahalanobis = torch.matmul(x_sub_mu_t, cov_matrix_inv_expanded)\n",
    "#     mahalanobis = torch.matmul(mahalanobis, x_sub_mu).squeeze(-1).squeeze(-1)\n",
    "#     e = torch.exp(-0.5 * mahalanobis)\n",
    "#     g = torch.sum(e, dim=2, keepdim=True)\n",
    "#     g_max = torch.clamp(g, min=1e-8)\n",
    "#     e_norm = e / g_max\n",
    "#     y_hat = torch.sum(e_norm * w.unsqueeze(-1), dim=2)\n",
    "#     y_hat = y_hat.view(-1, 3, height, width)\n",
    "#     y_hat = torch.clamp(y_hat, min=0, max=1)\n",
    "#     return y_hat\n",
    "\n",
    "\n",
    "# def forward(height, width, num_kernels, alpha, p):\n",
    "#     gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "#     mu = gaussians.mu  # [batch_size, ch, num_kernels, 2]\n",
    "#     cov_matrix = gaussians.cov_matrix  # [batch_size, ch, num_kernels, 2, 2]\n",
    "#     w = gaussians.w  # [batch_size, ch, num_kernels]\n",
    "\n",
    "#     grid = grid_f(height, width).to(p.device)  # [height, width, 2]\n",
    "#     grid_expand_dim = grid.unsqueeze(0).unsqueeze(0)  # [1, 1, height, width, 2]\n",
    "#     x = grid_expand_dim.expand(mu.shape[0], mu.shape[1], -1, -1, -1)  # [batch_size, ch, height, width, 2]\n",
    "\n",
    "#     mu = mu.unsqueeze(2).unsqueeze(2)  # [batch_size, ch, 1, 1, num_kernels, 2]\n",
    "#     x_sub_mu = (x.unsqueeze(4) - mu).unsqueeze(-1)  # [batch_size, ch, height, width, num_kernels, 2, 1]\n",
    "\n",
    "#     # Corrected einsum operation to use cov_matrix twice and include torch.negative\n",
    "#     e = torch.exp(\n",
    "#         torch.negative(\n",
    "#             0.5 * torch.einsum(\n",
    "#                 \"bchwdki,bcklm,bckmn,bchwdnj->bchwdk\",\n",
    "#                 x_sub_mu,\n",
    "#                 cov_matrix,\n",
    "#                 cov_matrix,\n",
    "#                 x_sub_mu\n",
    "#             ).squeeze(-1).squeeze(-1)\n",
    "#         )\n",
    "#     )  # [batch_size, ch, height, width, num_kernels]\n",
    "\n",
    "#     g = torch.sum(e, dim=4, keepdim=True)  # [batch_size, ch, height, width, 1]\n",
    "#     g_max = torch.clamp(g, min=1e-8)\n",
    "#     e_norm = e / g_max\n",
    "\n",
    "#     y_hat = torch.sum(e_norm * w.unsqueeze(2).unsqueeze(2), dim=4)  # [batch_size, ch, height, width]\n",
    "#     y_hat = torch.clamp(y_hat, min=0, max=1)\n",
    "\n",
    "#     return y_hat\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Gaussians:\n",
    "    mu: Tensor\n",
    "    cov_matrix: Tensor\n",
    "    w: Tensor\n",
    "\n",
    "def extract_params(p, k, alpha):\n",
    "    mu_x = p[:, :, :k].reshape(-1, 3, k, 1)\n",
    "    mu_y = p[:, :, k:2*k].reshape(-1, 3, k, 1)\n",
    "    mu = torch.cat((mu_x, mu_y), -1).view(-1, 3, k, 2)\n",
    "    scale_idx = 3 * k\n",
    "    scale = p[:, :, scale_idx:scale_idx + 2*k].reshape(-1, 3, k, 2)\n",
    "    rot_idx = scale_idx + 2 * k\n",
    "    theta = p[:, :, rot_idx:rot_idx + k].reshape(-1, 3, k)\n",
    "    cov_matrix = cov_mat_2d(scale, theta)\n",
    "    cov_matrix = torch.mul(cov_matrix, alpha)\n",
    "    w = p[:, :, 2*k:3*k].reshape(-1, 3, k)\n",
    "    return Gaussians(mu, cov_matrix, w)\n",
    "\n",
    "def cov_mat_2d(scale, theta, epsilon=1e-8):\n",
    "    scale_mat = torch.diag_embed(scale + epsilon)\n",
    "    R = ang_to_rot_mat(theta)\n",
    "    return R @ scale_mat @ scale_mat.transpose(-2, -1) @ R.transpose(-2, -1)\n",
    "\n",
    "def ang_to_rot_mat(theta):\n",
    "    cos_theta = torch.cos(theta).unsqueeze(-1)\n",
    "    sin_theta = torch.sin(theta).unsqueeze(-1)\n",
    "    R = torch.cat([cos_theta, -sin_theta, sin_theta, cos_theta], dim=-1)\n",
    "    return R.view(*theta.shape, 2, 2)\n",
    "\n",
    "\n",
    "def grid_f(height, width, channels):\n",
    "    y = torch.linspace(-1, 1, height)\n",
    "    x = torch.linspace(-1, 1, width)\n",
    "    grid_y, grid_x = torch.meshgrid(y, x, indexing='ij')\n",
    "    grid = torch.stack((grid_x, grid_y), dim=-1)  # [height, width, 2]\n",
    "    grid = grid.unsqueeze(0).expand(channels, -1, -1, -1)  # [channels, height, width, 2]\n",
    "    return grid\n",
    "\n",
    "\n",
    "def forward(height, width, num_kernels, alpha, p):\n",
    "    gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "    mu = gaussians.mu  # [batch_size, ch, num_kernels, 2]\n",
    "    cov_matrix = gaussians.cov_matrix  # [batch_size, ch, num_kernels, 2, 2]\n",
    "    w = gaussians.w  # [batch_size, ch, num_kernels]\n",
    "\n",
    "    grid = grid_f(height, width).to(p.device)  # [height, width, 2]\n",
    "\n",
    "    print(f'grid shape: {grid.shape}')\n",
    "\n",
    "    grid_expand_dim = grid.unsqueeze(0).unsqueeze(0)  # [1, 1, height, width, 2]\n",
    "    x = grid_expand_dim.expand(mu.shape[0], mu.shape[1], -1, -1, -1)  # [batch_size, ch, height, width, 2]\n",
    "\n",
    "    mu = mu.unsqueeze(2).unsqueeze(2)  # [batch_size, ch, 1, 1, num_kernels, 2]\n",
    "    x_sub_mu = (x.unsqueeze(4) - mu).unsqueeze(-1)  # [batch_size, ch, height, width, num_kernels, 2, 1]\n",
    "\n",
    "    \n",
    "    print(f'cov_matrix shape: {cov_matrix.shape}')  \n",
    "    print(f'x_sub_mu shape: {x_sub_mu.shape}')\n",
    "\n",
    "\n",
    "    e = torch.exp(\n",
    "        torch.negative(\n",
    "            0.5 * torch.einsum(\"bchwdki,bcklm,bckmn,bchwdnj->bchwdk\", x_sub_mu, cov_matrix, cov_matrix, x_sub_mu)\n",
    "        )\n",
    "    )  # [batch_size, ch, height, width, num_kernels]\n",
    "\n",
    "    g = torch.sum(e, dim=4, keepdim=True)  # [batch_size, ch, height, width, 1]\n",
    "    g_max = torch.clamp(g, min=1e-8)\n",
    "    e_norm = e / g_max\n",
    "\n",
    "    y_hat = torch.sum(e_norm * w.unsqueeze(2).unsqueeze(2), dim=4)  # [batch_size, ch, height, width]\n",
    "    y_hat = torch.clamp(y_hat, min=0, max=1)\n",
    "\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1, 63])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 9\n",
    "color = 1\n",
    "num_kernels = 9\n",
    "alpha = 1.0\n",
    "height = 16\n",
    "width = 16\n",
    "\n",
    "z = 2 * num_kernels + 4 * num_kernels + num_kernels\n",
    "print(z)\n",
    "p = torch.randn(batch_size, color, z)  \n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu shape: torch.Size([3, 3, 9, 2])\n",
      "cov_matrix shape: torch.Size([3, 3, 9, 2, 2])\n",
      "w shape: torch.Size([3, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "print(\"mu shape:\", gaussians.mu.shape)  # Expected: [27, 3, 9, 2]\n",
    "print(\"cov_matrix shape:\", gaussians.cov_matrix.shape)  # Expected: [27, 3, 9, 2, 2]\n",
    "print(\"w shape:\", gaussians.w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid shape: torch.Size([16, 16, 2])\n",
      "cov_matrix shape: torch.Size([3, 3, 9, 2, 2])\n",
      "x_sub_mu shape: torch.Size([3, 3, 16, 16, 9, 2, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Size of label 'k' for operand 1 (2) does not match previous terms (9).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[198], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_kernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[195], line 137\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(height, width, num_kernels, alpha, p)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov_matrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcov_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_sub_mu shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_sub_mu\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[1;32m    136\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnegative(\n\u001b[0;32m--> 137\u001b[0m         \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbchwdki,bcklm,bckmn,bchwdnj->bchwdk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sub_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sub_mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m )  \u001b[38;5;66;03m# [batch_size, ch, height, width, num_kernels]\u001b[39;00m\n\u001b[1;32m    141\u001b[0m g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(e, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# [batch_size, ch, height, width, 1]\u001b[39;00m\n\u001b[1;32m    142\u001b[0m g_max \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(g, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/functional.py:390\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    389\u001b[0m     _opt_einsum \u001b[38;5;241m=\u001b[39m opt_einsum\u001b[38;5;241m.\u001b[39mget_opt_einsum()\n\u001b[0;32m--> 390\u001b[0m     tupled_path \u001b[38;5;241m=\u001b[39m \u001b[43m_opt_einsum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontract_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_einsum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# flatten path for dispatching to C++\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     path \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tupled_path \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pair]\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/opt_einsum/contract.py:238\u001b[0m, in \u001b[0;36mcontract_path\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         size_dict[char] \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, size_dict[char]):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for operand \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) does not match previous \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterms (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(char, tnum, size_dict[char], dim))\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     size_dict[char] \u001b[38;5;241m=\u001b[39m dim\n",
      "\u001b[0;31mValueError\u001b[0m: Size of label 'k' for operand 1 (2) does not match previous terms (9)."
     ]
    }
   ],
   "source": [
    "y_hat = forward(height, width, num_kernels, alpha, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 64, 64])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.4255))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.min(), y_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu shape: torch.Size([3, 3, 9, 2])\n",
      "cov_matrix shape: torch.Size([3, 3, 9, 2, 2])\n",
      "w shape: torch.Size([3, 3, 9])\n",
      "grid shape: torch.Size([3, 3, 16, 16, 2])\n",
      "cov_matrix shape: torch.Size([3, 3, 9, 2, 2])\n",
      "x_sub_mu shape: torch.Size([3, 3, 16, 16, 9, 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Size of label 'k' for operand 1 (2) does not match previous terms (9).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[219], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcov_matrix shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gaussians\u001b[38;5;241m.\u001b[39mcov_matrix\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected: [batch_size, ch, num_kernels, 2, 2]\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gaussians\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected: [batch_size, ch, num_kernels]\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_kernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_hat shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_hat\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Expected: [batch_size, ch, height, width]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[219], line 64\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(height, width, num_kernels, alpha, p)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcov_matrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcov_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_sub_mu shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_sub_mu\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbchwdk,bckij,bchwdj->bchw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sub_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sub_mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     68\u001b[0m g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(e, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m g_max \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(g, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/torch/functional.py:390\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    389\u001b[0m     _opt_einsum \u001b[38;5;241m=\u001b[39m opt_einsum\u001b[38;5;241m.\u001b[39mget_opt_einsum()\n\u001b[0;32m--> 390\u001b[0m     tupled_path \u001b[38;5;241m=\u001b[39m \u001b[43m_opt_einsum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontract_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_einsum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# flatten path for dispatching to C++\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     path \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tupled_path \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m pair]\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.11/site-packages/opt_einsum/contract.py:238\u001b[0m, in \u001b[0;36mcontract_path\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         size_dict[char] \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, size_dict[char]):\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for operand \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) does not match previous \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterms (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(char, tnum, size_dict[char], dim))\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     size_dict[char] \u001b[38;5;241m=\u001b[39m dim\n",
      "\u001b[0;31mValueError\u001b[0m: Size of label 'k' for operand 1 (2) does not match previous terms (9)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Gaussians:\n",
    "    mu: Tensor\n",
    "    cov_matrix: Tensor\n",
    "    w: Tensor\n",
    "\n",
    "def extract_params(p, k, alpha):\n",
    "    mu_x = p[:, :, :k].reshape(-1, 3, k, 1)\n",
    "    mu_y = p[:, :, k:2*k].reshape(-1, 3, k, 1)\n",
    "    mu = torch.cat((mu_x, mu_y), -1).view(-1, 3, k, 2)\n",
    "    scale_idx = 3 * k\n",
    "    scale = p[:, :, scale_idx:scale_idx + 2*k].reshape(-1, 3, k, 2)\n",
    "    rot_idx = scale_idx + 2 * k\n",
    "    theta = p[:, :, rot_idx:rot_idx + k].reshape(-1, 3, k)\n",
    "    cov_matrix = cov_mat_2d(scale, theta)\n",
    "    cov_matrix = torch.mul(cov_matrix, alpha)\n",
    "    w = p[:, :, 2*k:3*k].reshape(-1, 3, k)\n",
    "    return Gaussians(mu, cov_matrix, w)\n",
    "\n",
    "def cov_mat_2d(scale, theta, epsilon=1e-8):\n",
    "    scale_mat = torch.diag_embed(scale + epsilon)\n",
    "    R = ang_to_rot_mat(theta)\n",
    "    return R @ scale_mat @ scale_mat.transpose(-2, -1) @ R.transpose(-2, -1)\n",
    "\n",
    "def ang_to_rot_mat(theta):\n",
    "    cos_theta = torch.cos(theta).unsqueeze(-1)\n",
    "    sin_theta = torch.sin(theta).unsqueeze(-1)\n",
    "    R = torch.cat([cos_theta, -sin_theta, sin_theta, cos_theta], dim=-1)\n",
    "    return R.view(*theta.shape, 2, 2)\n",
    "\n",
    "def grid_f(height, width, channels):\n",
    "    y = torch.linspace(-1, 1, height)\n",
    "    x = torch.linspace(-1, 1, width)\n",
    "    grid_y, grid_x = torch.meshgrid(y, x, indexing='ij')\n",
    "    grid = torch.stack((grid_x, grid_y), dim=-1)  # [height, width, 2]\n",
    "    grid = grid.unsqueeze(0).expand(channels, -1, -1, -1)  # [channels, height, width, 2]\n",
    "    return grid\n",
    "\n",
    "def forward(height, width, num_kernels, alpha, p):\n",
    "    gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "    mu = gaussians.mu\n",
    "    cov_matrix = gaussians.cov_matrix\n",
    "    w = gaussians.w\n",
    "\n",
    "    grid = grid_f(height, width, mu.shape[1]).to(p.device)\n",
    "    grid_expand_dim = grid.unsqueeze(0)\n",
    "    x = grid_expand_dim.expand(mu.shape[0], -1, -1, -1, -1)\n",
    "\n",
    "    print(f'grid shape: {x.shape}')\n",
    "\n",
    "    mu = mu.unsqueeze(2).unsqueeze(2)\n",
    "    x_sub_mu = (x.unsqueeze(4) - mu).unsqueeze(-1).squeeze(-1)  # Remove last dimension\n",
    "\n",
    "    print(f'cov_matrix shape: {cov_matrix.shape}')\n",
    "    print(f'x_sub_mu shape: {x_sub_mu.shape}')\n",
    "\n",
    "    \n",
    "    e = torch.exp(\n",
    "    -0.5 * torch.einsum(\"bchwdk,bckij,bchwdj->bchw\", x_sub_mu, cov_matrix, x_sub_mu)\n",
    "    )\n",
    "\n",
    "\n",
    "    g = torch.sum(e, dim=4, keepdim=True)\n",
    "    g_max = torch.clamp(g, min=1e-8)\n",
    "    e_norm = e / g_max\n",
    "\n",
    "    y_hat = torch.sum(e_norm * w.unsqueeze(2).unsqueeze(2), dim=4)\n",
    "    y_hat = torch.clamp(y_hat, min=0, max=1)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "# Test the code\n",
    "batch_size = 3\n",
    "color = 3\n",
    "num_kernels = 9\n",
    "alpha = 1.0\n",
    "height = 16\n",
    "width = 16\n",
    "\n",
    "z = 2 * num_kernels + 4 * num_kernels + num_kernels\n",
    "p = torch.randn(batch_size, color, z)\n",
    "\n",
    "gaussians = extract_params(p, num_kernels, alpha)\n",
    "\n",
    "print(\"mu shape:\", gaussians.mu.shape)  # Expected: [batch_size, ch, num_kernels, 2]\n",
    "print(\"cov_matrix shape:\", gaussians.cov_matrix.shape)  # Expected: [batch_size, ch, num_kernels, 2, 2]\n",
    "print(\"w shape:\", gaussians.w.shape)  # Expected: [batch_size, ch, num_kernels]\n",
    "\n",
    "y_hat = forward(height, width, num_kernels, alpha, p)\n",
    "print(\"y_hat shape:\", y_hat.shape)  # Expected: [batch_size, ch, height, width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
